DOCUMENT TITLE: The NIST AI Risk Management Framework (AI RMF 1.0) - Core Concepts

SOURCE: National Institute of Standards and Technology (NIST)

DOCUMENT TYPE: Framework Overview

DATE: January 26, 2023

---
OVERVIEW:

The AI Risk Management Framework (AI RMF) is a voluntary framework intended for use by organizations designing, developing, or deploying AI systems to help manage the numerous risks associated with AI. It is not a prescriptive checklist but a flexible, structured process.

The framework is organized around four core functions:

1.  **GOVERN:** This function is about cultivating a culture of risk management within an organization. It involves creating clear lines of responsibility, ensuring transparency, and engaging with stakeholders. A key aspect of GOVERN is creating processes to address risks associated with third-party AI models and data sources.

2.  **MAP:** This function involves identifying the specific context and risks for an AI system. Organizations are encouraged to inventory their AI systems, categorize them based on potential impact, and map out potential sources of algorithmic bias, security vulnerabilities, and privacy issues. The MAP function stresses the importance of understanding limitations and potential failures before deployment.

3.  **MEASURE:** This function focuses on testing, evaluating, and monitoring AI risks. It involves using quantitative and qualitative metrics to assess fairness, accuracy, robustness, and security. A key challenge highlighted in MEASURE is the difficulty of testing for emergent, unexpected behaviors in complex foundation models. It recommends ongoing monitoring after a system is deployed.

4.  **MANAGE:** This function is about allocating resources to mitigate identified risks. Based on the outputs from the MAP and MEASURE functions, organizations should prioritize risks and deploy appropriate controls. This could include technical controls like de-biasing algorithms, procedural controls like human oversight, or documenting the known limitations of the AI system for end-users. The framework emphasizes that risks should be managed on a continuous basis, not just at a single point in time.
