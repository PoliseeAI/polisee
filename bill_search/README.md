You must have an `.env` file defining a `SUPABASE_DB_URL` and `OPENAI_API_KEY`.

Install requirements with `pip install -r requirements.txt`


Run `python enrich_summaries.py` to update the vector embeddings on Supabase for the AI summaries.

Then test the endpoint by running `python query_engine.py` with your persona e.g.:

```bash
python query_engine.py "I'm a farmer in the Midwest concerned about water rights and international trade."
```

NEXT STEP: deploy the `query_engine.py` endpoint to the web and update the frontend to make use of it.

Note that this functionality makes use of the following tables/functions that were added on Supabase:

```sql
-- Step 1: Create the new table for our granular, searchable embeddings.
-- This will store each individual point from your AI summaries.
CREATE TABLE summary_embeddings (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    summary_id BIGINT NOT NULL REFERENCES ai_bill_summaries(id) ON DELETE CASCADE,
    bill_table_id INT NOT NULL REFERENCES bills(id) ON DELETE CASCADE,
    source_column TEXT NOT NULL, -- e.g., 'what_it_does', 'key_changes', 'who_it_affects'
    chunk_text TEXT NOT NULL,
    embedding vector(1536) NOT NULL, -- For OpenAI's text-embedding-3-small
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Step 2: Add a column to the source table to track processing status.
-- This prevents re-processing the same summary over and over.
ALTER TABLE ai_bill_summaries
ADD COLUMN is_embedded BOOLEAN DEFAULT FALSE;

-- Step 3: Create a high-performance index for fast vector similarity search.
-- This is crucial for the query engine's performance.
CREATE INDEX ON summary_embeddings
USING HNSW (embedding vector_cosine_ops);

-- Step 4: Create a PostgreSQL function for performing the vector search.
-- Calling a DB function from your edge function is more secure and efficient.
CREATE OR REPLACE FUNCTION match_summary_chunks (
  query_embedding vector(1536),
  match_threshold float,
  match_count int
)
RETURNS TABLE (
  id BIGINT,
  summary_id BIGINT,
  bill_table_id INT,
  chunk_text TEXT,
  source_column TEXT,
  similarity float
)
AS $$
BEGIN
  RETURN QUERY
  SELECT
    se.id,
    se.summary_id,
    se.bill_table_id,
    se.chunk_text,
    se.source_column,
    1 - (se.embedding <=> query_embedding) AS similarity
  FROM
    summary_embeddings AS se
  WHERE 1 - (se.embedding <=> query_embedding) > match_threshold
  ORDER BY
    similarity DESC
  LIMIT
    match_count;
END;
$$
LANGUAGE plpgsql;
```
